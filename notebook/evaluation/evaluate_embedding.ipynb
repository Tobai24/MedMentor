{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from langchain_core.documents import Document\n",
        "from pinecone import ServerlessSpec\n",
        "from pinecone import Pinecone\n",
        "from dotenv import load_dotenv\n",
        "from sentence_transformers import CrossEncoder\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "EMBEDDINGS = OpenAIEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('documents_with_ids.json', 'rt') as f_in:\n",
        "    documents = json.load(f_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select the sample used to create the ground truth\n",
        "documents = documents[2100: 2150] + documents[4100: 4200] + documents[1100: 1150] + documents[3100: 3150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'page_content': 'CHAPTER 5   THE CARdiAC ExAminATion 83\\nRate of pulse\\nPractised observers can estimate the rate quickly. Formal \\ncounting over 30 seconds is accurate and requires only \\nsimple mathematics to obtain the rate per minute. The \\nnormal resting heart rate in adults is usually said to be \\nbetween 60 and 100 beats per minute but a more \\nsensible range is probably 55 to 95 (95% of normal \\npeople). Bradycardia (from the Greek bradys ‘slow’ , \\nkardia ‘heart’) is defined as a heart rate of less than 60 \\nbeats per minute. Tachycardia (from the Greek tachys \\n‘swift’ , kardia ‘heart’) is defined as a heart rate over 100 \\nbeats per minute (see the OSCE ECGs nos 2, 3 and 4 \\nat ). The causes of bradycardia and \\ntachycardia are listed in Table 5.1.\\nRhythm\\nThe rhythm of the pulse can be regular or irregular. An \\nirregular rhythm can be completely irregular with no \\npattern (irregularly irregular or chaotic rhythm); this is \\nusually due to atrial fibrillation (see Table 5.1). In atrial',\n",
              " 'metadata': {'source': '../data/Talley.pdf',\n",
              "  'page': 108,\n",
              "  'page_label': '109'},\n",
              " 'id': 'e84c82d5'}"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_chunk_embedding(documents):\n",
        "    \n",
        "    processed_docs = [\n",
        "    Document(page_content=doc[\"page_content\"], metadata={\"id\": doc[\"id\"]})\n",
        "    for doc in documents]\n",
        "\n",
        "    # OpenAI Embeddings\n",
        "    openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    faiss_index_openai = FAISS.from_documents(processed_docs, openai_embeddings)\n",
        "    openai_index_path = \"../embeddings/faiss_index_openai\"\n",
        "    faiss_index_openai.save_local(openai_index_path)\n",
        "\n",
        "    return {\"openai_index\": openai_index_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_path_one = create_chunk_embedding(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and Query FAISS retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_faiss_index(index_path):\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    faiss_index = FAISS.load_local(\n",
        "        index_path,\n",
        "        embeddings,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "    return faiss_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_faiss_index(faiss_index, query, k=20):\n",
        "    query_text = query[\"question\"]\n",
        "    results = faiss_index.similarity_search(query_text, k=k)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_index = load_faiss_index(\"../embeddings/faiss_index_openai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ground_truth = pd.read_csv('questions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "ground_truth = df_ground_truth.to_dict(orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Assessment of bradycardia or tachycardia',\n",
              " 'case_prompt': 'A 68-year-old male presents to the clinic with complaints of lightheadedness and palpitations for the past week.',\n",
              " 'document': 'e84c82d5'}"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code to evaluate retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hit_rate(relevance_total):\n",
        "    cnt = 0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        if True in line:\n",
        "            cnt = cnt + 1\n",
        "\n",
        "    return cnt / len(relevance_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mrr(relevance_total):\n",
        "    total_score = 0.0\n",
        "\n",
        "    for line in relevance_total:\n",
        "        for rank in range(len(line)):\n",
        "            if line[rank] == True:\n",
        "                total_score = total_score + 1 / (rank + 1)\n",
        "\n",
        "    return total_score / len(relevance_total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Faiss retreival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(ground_truth):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']\n",
        "        results = query_faiss_index(first_index, q, k=30)\n",
        "        relevance = [d.metadata[\"id\"] == doc_id for d in results]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [03:28<00:00,  1.20it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'hit_rate': 0.92, 'mrr': 0.5351691156908999}"
            ]
          },
          "execution_count": 219,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# semantic search result\n",
        "evaluate(ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Faiss retrival with reranking evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rerank_documents(query, retrieved_docs):\n",
        "    pairs = []\n",
        "    for doc in retrieved_docs:\n",
        "        text = doc.page_content  \n",
        "        \n",
        "        if text is None:\n",
        "            print(f\"Warning: Missing 'page_content' in metadata for document ID {doc.metadata.get('id', 'Unknown')}\")\n",
        "            continue \n",
        "        \n",
        "        pairs.append((query, text))\n",
        "    \n",
        "    if not pairs:\n",
        "        print(\"No valid documents found for reranking.\")\n",
        "        return []\n",
        "    \n",
        "    scores = reranker.predict(pairs)\n",
        "    reranked_docs = [doc for _, doc in sorted(zip(scores, retrieved_docs), key=lambda x: x[0], reverse=True)]\n",
        "    \n",
        "    return reranked_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_reranking(ground_truth):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']\n",
        "        query_text = q['question']\n",
        "        \n",
        "        retrieved_results =  query_faiss_index(first_index, q, k=30)\n",
        "\n",
        "        reranked_results = rerank_documents(query_text, retrieved_results)\n",
        "\n",
        "        relevance = [d.metadata[\"id\"] == doc_id for d in reranked_results]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [18:27<00:00,  4.43s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'hit_rate': 0.92, 'mrr': 0.6199280855376507}"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_with_reranking(ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Pinecone Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "def generate_embeddings(documents):\n",
        "    texts = [doc[\"page_content\"] for doc in documents] \n",
        "    embeddings = embeddings_model.embed_documents(texts) \n",
        "    return embeddings\n",
        "\n",
        "# Example usage\n",
        "chunked_document_embeddings = generate_embeddings(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 250 embeddings.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Generated {len(chunked_document_embeddings)} embeddings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_vector_and_text(documents: list[dict], doc_embeddings: list[list[float]]) -> list[dict]:\n",
        "    data_with_metadata = []\n",
        "\n",
        "    for doc, embedding in zip(documents, doc_embeddings):\n",
        "        data_item = {\n",
        "            \"id\": str(doc.get(\"id\", \"unknown_id\")),\n",
        "            \"values\": embedding, \n",
        "            \"metadata\": {\"page_content\": doc.get(\"page_content\", \"\"), \"id\": str(doc.get(\"id\", \"unknown_id\"))},\n",
        "        }\n",
        "        data_with_metadata.append(data_item)\n",
        "\n",
        "    return data_with_metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = combine_vector_and_text(documents=documents, doc_embeddings=chunked_document_embeddings) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.create_index(\n",
        "name=\"final\",\n",
        "dimension=1536,\n",
        "metric=\"cosine\",\n",
        "spec=ServerlessSpec(\n",
        "cloud='aws',\n",
        "region='us-east-1'\n",
        ")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = pc.Index(\"final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsert_data_to_pinecone(data_with_metadata: list[dict[str, any]], chunk_size: int = 1000) -> None:\n",
        "    \n",
        "    for i in range(0, len(data_with_metadata), chunk_size):\n",
        "        chunk = data_with_metadata[i:i + chunk_size]\n",
        "        index.upsert(vectors=chunk)\n",
        "\n",
        "\n",
        "upsert_data_to_pinecone(data_with_metadata= data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_query_embeddings(query: str) -> list[float]:\n",
        "    query_embeddings = EMBEDDINGS.embed_query(query)\n",
        "    return query_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_pinecone_index(\n",
        "    query_embeddings: list, top_k: int = 20, include_metadata: bool = True\n",
        ") -> dict[str, any]:\n",
        "    query_response = index.query(\n",
        "        vector=query_embeddings, top_k=top_k, include_metadata=include_metadata\n",
        "    )\n",
        "    return query_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pinecone(ground_truth):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']  \n",
        "        query_text = q['question']\n",
        "        embeddings = get_query_embeddings(query_text) \n",
        "        results = query_pinecone_index(embeddings, top_k=30)\n",
        "        \n",
        "        relevance = [match[\"metadata\"][\"id\"] == doc_id for match in results[\"matches\"]]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [03:55<00:00,  1.06it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'hit_rate': 0.92, 'mrr': 0.5272179545726603}"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_pinecone(ground_truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Document reranking to improve Pinecone retrival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rerank_documents(query, retrieved_docs):\n",
        "    \n",
        "    pairs = []\n",
        "    doc_list = []\n",
        "\n",
        "    for doc in retrieved_docs[\"matches\"]:\n",
        "        text = doc[\"metadata\"].get(\"page_content\") \n",
        "        # if text is None:\n",
        "        #     print(f\"Warning: Missing 'page_content' in metadata for document ID {doc['metadata'].get('id', 'Unknown')}\")\n",
        "        #     continue \n",
        "        \n",
        "        pairs.append((query, text))\n",
        "        doc_list.append(doc)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"No valid documents found for reranking.\")\n",
        "        return []\n",
        "\n",
        "    scores = reranker.predict(pairs)\n",
        "\n",
        "    scored_docs = list(zip(scores, doc_list))\n",
        "    scored_docs.sort(key=lambda x: x[0], reverse=True)\n",
        "    reranked_docs = [doc for _, doc in scored_docs]\n",
        "    \n",
        "    return reranked_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pinecone_reranking(ground_truth):\n",
        "    relevance_total = []\n",
        "\n",
        "    for q in tqdm(ground_truth):\n",
        "        doc_id = q['document']\n",
        "        query_text = q['question']\n",
        "        \n",
        "        embeddings = get_query_embeddings(query_text)\n",
        "        retrieved_results = query_pinecone_index(embeddings, top_k=30)\n",
        "\n",
        "        reranked_results = rerank_documents(query_text, retrieved_results)\n",
        "\n",
        "        relevance = [match[\"metadata\"][\"id\"] == doc_id for match in reranked_results]\n",
        "        relevance_total.append(relevance)\n",
        "\n",
        "    return {\n",
        "        'hit_rate': hit_rate(relevance_total),\n",
        "        'mrr': mrr(relevance_total),\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 250/250 [17:55<00:00,  4.30s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'hit_rate': 0.92, 'mrr': 0.6199398867798867}"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_pinecone_reranking(ground_truth)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "MedMentor-4DQmH_3Z",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
